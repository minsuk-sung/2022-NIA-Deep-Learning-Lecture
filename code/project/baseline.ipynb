{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "133631a0",
   "metadata": {},
   "source": [
    "![](../../img/banner_day3.png)\n",
    "\n",
    "<br>\n",
    "\n",
    "# 3일차 실습(5) - 실전 프로젝트 베이스라인\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<div align='right'>강사 성민석</div>\n",
    "<div align='right'>고려대학교 인공지능학과 박사과정</div>\n",
    "<div align='right'>(minsuksung@korea.ac.kr)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ded8c6",
   "metadata": {},
   "source": [
    "> <font color='red'><b>WARNING</b></font>: 본 컨텐츠는 **[저작권법 제25조 제2항](https://glaw.scourt.go.kr/wsjo/lawod/sjo192.do?contId=2135829&jomunNo=25)** 에 의해 강의 목적으로 이용한 저작물이 포함되어 있습니다.  \n",
    "> 해당 자료를 제작자의 동의없이 <font color='red'><b>외부에 임의로 공개 및 수정하는 것을 금지</b></font>하며 이를 위반하는 경우 저작권 침해로서 관련법에 따라 처벌될 수 있으니 주의해주시기 바랍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f24954f",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>목차<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#프로젝트-소개\" data-toc-modified-id=\"프로젝트-소개-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>프로젝트 소개</a></span></li><li><span><a href=\"#참고자료\" data-toc-modified-id=\"참고자료-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>참고자료</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb072aa",
   "metadata": {},
   "source": [
    "## 프로젝트 소개\n",
    "<hr style=\"height:5px;border:none;color:#132e4f;background-color:#132e4f;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1020a74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T14:18:48.004653Z",
     "start_time": "2022-09-01T14:18:46.558398Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import fire\n",
    "import yaml\n",
    "import random\n",
    "import torch\n",
    "import shutil\n",
    "import argparse\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from psutil import virtual_memory\n",
    "\n",
    "from flags import Flags\n",
    "from checkpoint import (\n",
    "    default_checkpoint,\n",
    "    load_checkpoint,\n",
    "    save_checkpoint,\n",
    "    init_tensorboard,\n",
    "    write_tensorboard,\n",
    ")\n",
    "from utils import get_network, get_optimizer\n",
    "from dataset import get_train_valid_dataloader\n",
    "from metrics import accuracy, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e1ff9b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T14:18:48.013941Z",
     "start_time": "2022-09-01T14:18:48.006668Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_epoch(\n",
    "    options,\n",
    "    data_loader,\n",
    "    model,\n",
    "    epoch_text,\n",
    "    optimizer,\n",
    "    lr_scheduler,\n",
    "    train=True,\n",
    "):\n",
    "    torch.set_grad_enabled(train)\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    losses = []\n",
    "    acces = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "\n",
    "    with tqdm(\n",
    "        desc=\"{} ({})\".format(epoch_text, \"Train\" if train else \"Valid\"),\n",
    "        total=len(data_loader.dataset),\n",
    "        dynamic_ncols=True,\n",
    "        leave=False,\n",
    "    ) as pbar:\n",
    "        for i, (images, targets) in enumerate(data_loader):\n",
    "            images = images.to(options.device, torch.float)\n",
    "            targets = targets.to(options.device, torch.long)\n",
    "\n",
    "            curr_batch_size = len(images)\n",
    "\n",
    "            scores = model(images).to(options.device)\n",
    "            _, preds = scores.max(dim=1)\n",
    "\n",
    "            loss = F.cross_entropy(scores, targets)\n",
    "            acc = accuracy(targets, preds, options.batch_size)\n",
    "            pre = precision(targets, preds)\n",
    "            rec = recall(targets, preds)\n",
    "\n",
    "            if train:\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            acces.append(acc)\n",
    "            precisions.append(pre)\n",
    "            recalls.append(rec)\n",
    "\n",
    "            pbar.update(curr_batch_size)\n",
    "\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    result = {\n",
    "        \"loss\": np.mean(losses),\n",
    "        \"accuracy\": np.mean(acces),\n",
    "        \"precision\": np.mean(precisions),\n",
    "        \"recall\": np.mean(recalls),\n",
    "    }\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fe450dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T14:18:48.036689Z",
     "start_time": "2022-09-01T14:18:48.015639Z"
    }
   },
   "outputs": [],
   "source": [
    "def main(config_file):\n",
    "    options = Flags(config_file).get()\n",
    "\n",
    "    random.seed(options.seed)\n",
    "    np.random.seed(options.seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(options.seed)\n",
    "    torch.manual_seed(options.seed)\n",
    "    torch.cuda.manual_seed(options.seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = True  # type: ignore\n",
    "\n",
    "    is_cuda = torch.cuda.is_available()\n",
    "    print(\"--------------------------------\")\n",
    "    print(\"Running {} on device {}\\n\".format(options.network, options.device))\n",
    "\n",
    "    current_device = torch.cuda.current_device() if torch.cuda.is_available() else 'CPU'\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    num_cpus = os.cpu_count()\n",
    "    mem_size = virtual_memory().available // (1024 ** 3)\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\n",
    "        \"[+] System environments\\n\",\n",
    "        \"Device: {}\\n\".format(torch.cuda.get_device_name(current_device)),\n",
    "        \"Random seed : {}\\n\".format(options.seed),\n",
    "        \"The number of gpus : {}\\n\".format(num_gpus),\n",
    "        \"The number of cpus : {}\\n\".format(num_cpus),\n",
    "        \"Memory Size : {}G\\n\".format(mem_size),\n",
    "    )\n",
    "\n",
    "    checkpoint = (\n",
    "        load_checkpoint(options.checkpoint, cuda=is_cuda)\n",
    "        if options.checkpoint != \"\"\n",
    "        else default_checkpoint\n",
    "    )\n",
    "\n",
    "    train_data_loader, valid_data_loader, train_dataset, valid_dataset = get_train_valid_dataloader(\n",
    "        options)\n",
    "    print(\n",
    "        \"[+] Data\\n\",\n",
    "        \"Train path : {}\\n\".format(options.data.train),\n",
    "        \"Test path : {}\\n\".format(options.data.test),\n",
    "        \"Batch size : {}\\n\".format(options.batch_size),\n",
    "        \"Valid proportions : {}\\n\".format(options.data.test_proportions),\n",
    "        \"The number of train samples : {:,}\\n\".format(len(train_dataset)),\n",
    "        \"The number of valid samples : {:,}\\n\".format(len(valid_dataset)),\n",
    "    )\n",
    "\n",
    "    model = get_network(options)\n",
    "    model_state = checkpoint.get(\"model\")\n",
    "    if model_state:\n",
    "        model.load_state_dict(model_state)\n",
    "        print(\n",
    "            \"[+] Checkpoint\\n\",\n",
    "            \"Resuming from epoch : {}\\n\".format(checkpoint[\"epoch\"]),\n",
    "            \"Train Accuracy : {:.5f}\\n\".format(\n",
    "                checkpoint[\"train_accuracy\"][-1]),\n",
    "            \"Train Loss : {:.5f}\\n\".format(checkpoint[\"train_losses\"][-1]),\n",
    "            \"Valid Accuracy : {:.5f}\\n\".format(\n",
    "                checkpoint[\"valid_accuracy\"][-1]),\n",
    "            \"Valid Loss : {:.5f}\\n\".format(checkpoint[\"valid_losses\"][-1]),\n",
    "        )\n",
    "\n",
    "    params_to_optimise = [\n",
    "        param for param in model.parameters() if param.requires_grad\n",
    "    ]\n",
    "    print(\n",
    "        \"[+] Network\\n\",\n",
    "        \"Type: {}\\n\".format(options.network),\n",
    "        \"Model parameters: {:,}\\n\".format(\n",
    "            sum(p.numel() for p in params_to_optimise),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    optimizer = get_optimizer(params_to_optimise, options)\n",
    "    optimizer_state = checkpoint.get(\"optimizer\")\n",
    "    if optimizer_state:\n",
    "        optimizer.load_state_dict(optimizer_state)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group[\"initial_lr\"] = options.optimizer.lr\n",
    "\n",
    "    lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "    print(\n",
    "        \"[+] Optimizer\\n\",\n",
    "        \"Type: {}\\n\".format(options.optimizer.type),\n",
    "        \"Learning rate: {:,}\\n\".format(options.optimizer.lr),\n",
    "        \"Weight Decay: {:,}\\n\".format(options.optimizer.weight_decay),\n",
    "    )\n",
    "\n",
    "    if not os.path.exists(options.prefix):\n",
    "        os.makedirs(options.prefix)\n",
    "    log_file = open(os.path.join(options.prefix, \"log.txt\"), \"w\")\n",
    "    shutil.copy(config_file, os.path.join(options.prefix, \"train_config.yaml\"))\n",
    "\n",
    "    if options.print_epochs is None:\n",
    "        options.print_epochs = options.num_epochs\n",
    "\n",
    "    writer = init_tensorboard(name=options.prefix.strip(\"-\"))\n",
    "    start_epoch = checkpoint[\"epoch\"]\n",
    "    train_accuracy = checkpoint[\"train_accuracy\"]\n",
    "    train_recall = checkpoint[\"train_recall\"]\n",
    "    train_precision = checkpoint[\"train_precision\"]\n",
    "    train_losses = checkpoint[\"train_losses\"]\n",
    "    valid_accuracy = checkpoint[\"valid_accuracy\"]\n",
    "    valid_recall = checkpoint[\"valid_recall\"]\n",
    "    valid_precision = checkpoint[\"valid_precision\"]\n",
    "    valid_losses = checkpoint[\"valid_losses\"]\n",
    "    learning_rates = checkpoint[\"lr\"]\n",
    "\n",
    "    valid_early_stop = 0\n",
    "    valid_best_loss = float('inf')\n",
    "\n",
    "    for epoch in range(options.num_epochs):\n",
    "        start_time = time.time()\n",
    "\n",
    "        epoch_text = \"[{current:>{pad}}/{end}] Epoch {epoch}\".format(\n",
    "            current=start_epoch + epoch + 1,\n",
    "            end=start_epoch + options.num_epochs,\n",
    "            epoch=start_epoch + epoch + 1,\n",
    "            pad=len(str(options.num_epochs)),\n",
    "        )\n",
    "\n",
    "        train_result = run_epoch(\n",
    "            options,\n",
    "            train_data_loader,\n",
    "            model,\n",
    "            epoch_text,\n",
    "            optimizer,\n",
    "            lr_scheduler,\n",
    "            train=True,\n",
    "        )\n",
    "\n",
    "        train_losses.append(train_result[\"loss\"])\n",
    "        train_precision.append(train_result[\"precision\"])\n",
    "        train_recall.append(train_result[\"recall\"])\n",
    "        train_accuracy.append(train_result[\"accuracy\"])\n",
    "\n",
    "        epoch_lr = lr_scheduler.get_last_lr()[-1]\n",
    "\n",
    "        valid_result = run_epoch(\n",
    "            options,\n",
    "            valid_data_loader,\n",
    "            model,\n",
    "            epoch_text,\n",
    "            optimizer,\n",
    "            lr_scheduler,\n",
    "            train=False,\n",
    "        )\n",
    "\n",
    "        valid_losses.append(valid_result[\"loss\"])\n",
    "        valid_precision.append(valid_result[\"precision\"])\n",
    "        valid_recall.append(valid_result[\"recall\"])\n",
    "        valid_accuracy.append(valid_result[\"accuracy\"])\n",
    "\n",
    "        with open(config_file, 'r') as f:\n",
    "            option_dict = yaml.safe_load(f)\n",
    "\n",
    "        save_checkpoint(\n",
    "            {\n",
    "                \"epoch\": start_epoch + epoch + 1,\n",
    "                \"train_losses\": train_losses,\n",
    "                \"train_accuracy\": train_accuracy,\n",
    "                \"train_precision\": train_precision,\n",
    "                \"train_recall\": train_recall,\n",
    "                \"valid_losses\": valid_losses,\n",
    "                \"valid_accuracy\": valid_accuracy,\n",
    "                \"valid_precision\": valid_precision,\n",
    "                \"valid_recall\": valid_recall,\n",
    "                \"lr\": learning_rates,\n",
    "                \"model\": model.state_dict(),\n",
    "                \"optimizer\": optimizer.state_dict(),\n",
    "                \"configs\": option_dict,\n",
    "            },\n",
    "            prefix=options.prefix,\n",
    "        )\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "        elapsed_time = time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))\n",
    "        if epoch % options.print_epochs == 0 or epoch == options.num_epochs - 1:\n",
    "            output_string = (\n",
    "                \"{epoch_text}: \"\n",
    "                \"Train Accuracy = {train_accuracy:.5f}, \"\n",
    "                \"Train Precision = {train_precision:.5f}, \"\n",
    "                \"Train Recall = {train_recall:.5f}, \"\n",
    "                \"Train Loss = {train_loss:.5f}, \"\n",
    "                \"Valid Accuracy = {valid_accuracy:.5f}, \"\n",
    "                \"Valid Precision = {valid_precision:.5f}, \"\n",
    "                \"Valid Recall = {valid_recall:.5f}, \"\n",
    "                \"Valid Loss = {valid_loss:.5f}, \"\n",
    "                \"lr = {lr} \"\n",
    "                \"(time elapsed {time})\"\n",
    "            ).format(\n",
    "                epoch_text=epoch_text,\n",
    "                train_accuracy=train_result[\"accuracy\"],\n",
    "                train_precision=train_result[\"precision\"],\n",
    "                train_recall=train_result[\"recall\"],\n",
    "                train_loss=train_result[\"loss\"],\n",
    "                valid_accuracy=valid_result[\"accuracy\"],\n",
    "                valid_precision=valid_result[\"precision\"],\n",
    "                valid_recall=valid_result[\"recall\"],\n",
    "                valid_loss=valid_result[\"loss\"],\n",
    "                lr=epoch_lr,\n",
    "                time=elapsed_time,\n",
    "            )\n",
    "            print(output_string)\n",
    "            log_file.write(output_string + \"\\n\")\n",
    "            write_tensorboard(\n",
    "                writer,\n",
    "                start_epoch + epoch + 1,\n",
    "                train_result[\"loss\"],\n",
    "                train_result[\"accuracy\"],\n",
    "                train_result[\"precision\"],\n",
    "                train_result[\"recall\"],\n",
    "                valid_result[\"loss\"],\n",
    "                valid_result[\"accuracy\"],\n",
    "                valid_result[\"precision\"],\n",
    "                valid_result[\"recall\"],\n",
    "                model,\n",
    "            )\n",
    "\n",
    "        if valid_result[\"loss\"] < valid_best_loss:\n",
    "            valid_best_loss = valid_result[\"loss\"]\n",
    "            valid_early_stop = 0\n",
    "\n",
    "        else:\n",
    "            valid_early_stop += 1\n",
    "            if valid_early_stop >= options.EARLY_STOPPING_EPOCH:\n",
    "                print(\"EARLY STOPPING!!\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66c05e71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T14:20:58.336184Z",
     "start_time": "2022-09-01T14:18:48.037957Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Network\n",
      " Type: VGG\n",
      " Model parameters: 128,780,034\n",
      "\n",
      "[+] Optimizer\n",
      " Type: Adam\n",
      " Learning rate: 0.0001\n",
      " Weight Decay: 0.01\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1/20] Epoch 1: Train Accuracy = 0.58597, Train Precision = 0.59924, Train Recall = 0.57865, Train Loss = 0.72552, Valid Accuracy = 0.58075, Valid Precision = 0.55110, Valid Recall = 0.84699, Valid Loss = 0.67455, lr = 0.0001 (time elapsed 00:00:55)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2/20] Epoch 2: Train Accuracy = 0.67014, Train Precision = 0.68278, Train Recall = 0.68161, Train Loss = 0.60922, Valid Accuracy = 0.69663, Valid Precision = 0.75175, Valid Recall = 0.59657, Valid Loss = 0.58559, lr = 0.0001 (time elapsed 00:00:54)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-89f4b4259b33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'configs/VGG.yaml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-12f6b685489b>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(config_file)\u001b[0m\n\u001b[1;32m    216\u001b[0m                 \u001b[0mvalid_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"precision\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0mvalid_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"recall\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m                 \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m             )\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GitHub/2022-NIA-Deep-Learning-Lecture/code/project/checkpoint.py\u001b[0m in \u001b[0;36mwrite_tensorboard\u001b[0;34m(writer, epoch, train_loss, train_accuracy, train_precision, train_recall, valid_loss, valid_accuracy, valid_precision, valid_recall, model)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         writer.add_histogram(\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0;34m\"{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         )\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorboardX/writer.py\u001b[0m in \u001b[0;36madd_histogram\u001b[0;34m(self, tag, values, global_step, bins, walltime, max_bins)\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0mbins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_bins\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         self._get_file_writer().add_summary(\n\u001b[0;32m--> 559\u001b[0;31m             histogram(tag, values, bins, max_bins=max_bins), global_step, walltime)\n\u001b[0m\u001b[1;32m    560\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomet_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_histogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorboardX/summary.py\u001b[0m in \u001b[0;36mhistogram\u001b[0;34m(name, values, bins, max_bins)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_clean_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m     \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_histogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_bins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mSummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhisto\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorboardX/summary.py\u001b[0m in \u001b[0;36mmake_histogram\u001b[0;34m(values, bins, max_bins)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The input has no element.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m     \u001b[0mcounts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m     \u001b[0mnum_bins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmax_bins\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnum_bins\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmax_bins\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mhistogram\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/numpy/lib/histograms.py\u001b[0m in \u001b[0;36mhistogram\u001b[0;34m(a, bins, range, normed, weights, density)\u001b[0m\n\u001b[1;32m    875\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBLOCK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m                 \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mBLOCK\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    878\u001b[0m                 \u001b[0mcum_n\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0m_search_sorted_inclusive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbin_edges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msort\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msort\u001b[0;34m(a, axis, kind, order)\u001b[0m\n\u001b[1;32m    994\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"K\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 996\u001b[0;31m     \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    997\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main('configs/VGG.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ce3d86",
   "metadata": {},
   "source": [
    "## 참고자료\n",
    "<hr style=\"height:5px;border:none;color:#132e4f;background-color:#132e4f;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dec1acf",
   "metadata": {},
   "source": [
    "- ㅇㅇ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65da470",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<span style=\"color:rgb(120, 120, 120)\">본 학습 자료를 포함한 모든 자료의 저작권은 성민석에 있으며 제작자의 동의없이 외부로의 무단 복제, 배포 및 전송을 절대로 불허합니다.\n",
    "\n",
    "<b>Copyright ⓒ 2022. Minsuk Sung. All rights reserved.</b>\n",
    "</span>\n",
    "\n",
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "목차",
   "title_sidebar": "내용",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
